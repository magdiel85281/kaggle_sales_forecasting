{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.sales_data import SalesData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sales_train.csv:\t(2935849, 6)\n",
      "shops.csv:\t(60, 2)\n",
      "test.csv:\t(214200, 3)\n",
      "item_categories.csv:\t(84, 2)\n",
      "items.csv:\t(22170, 3)\n",
      "sample_submission.csv:\t(214200, 2)\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir('data'):\n",
    "    if '.csv' in filename:\n",
    "        df = pd.read_csv(f'data/{filename}')\n",
    "        print(f'{filename}:\\t{df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data and Format Columns\n",
    "Also, add year, month, and year_month columns. Then, aggregate to monthly sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = SalesData()\n",
    "sd.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.monthly_agg()\n",
    "sales = sd.monthly_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>year_month</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_mth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>01</td>\n",
       "      <td>201301</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>01</td>\n",
       "      <td>201301</td>\n",
       "      <td>0</td>\n",
       "      <td>1001</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>01</td>\n",
       "      <td>201301</td>\n",
       "      <td>0</td>\n",
       "      <td>10012</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>01</td>\n",
       "      <td>201301</td>\n",
       "      <td>0</td>\n",
       "      <td>1002</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>01</td>\n",
       "      <td>201301</td>\n",
       "      <td>0</td>\n",
       "      <td>1003</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  year month year_month shop_id item_id  item_price  \\\n",
       "0               0  2013    01     201301       0    1000        58.0   \n",
       "1               0  2013    01     201301       0    1001        58.0   \n",
       "2               0  2013    01     201301       0   10012        76.0   \n",
       "3               0  2013    01     201301       0    1002        58.0   \n",
       "4               0  2013    01     201301       0    1003        58.0   \n",
       "\n",
       "   item_cnt_mth  \n",
       "0           5.0  \n",
       "1           2.0  \n",
       "2           1.0  \n",
       "3           2.0  \n",
       "4           2.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1739022 entries, 0 to 1739021\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   date_block_num  int64  \n",
      " 1   year            int64  \n",
      " 2   month           object \n",
      " 3   year_month      object \n",
      " 4   shop_id         object \n",
      " 5   item_id         object \n",
      " 6   item_price      float64\n",
      " 7   item_cnt_mth    float64\n",
      "dtypes: float64(2), int64(2), object(4)\n",
      "memory usage: 106.1+ MB\n"
     ]
    }
   ],
   "source": [
    "sales.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models\n",
    "Get a baseline score using Gradient Boosting and Random Forest Regressors. First run used GridSearch to find best parameters... probably overkill for our baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_train_test_split(X, y, test_periods=1):\n",
    "    periods = sorted(list(X['year_month'].unique()))\n",
    "    train_periods = periods[:-test_periods]\n",
    "    test_periods = periods[-test_periods:]\n",
    "    \n",
    "    train_mask = X['year_month'].isin(train_periods)\n",
    "    X_train = X.loc[train_mask]\n",
    "    y_train = y.loc[train_mask]\n",
    "    \n",
    "    test_mask = X['year_month'].isin(test_periods)\n",
    "    X_test = X.loc[test_mask]\n",
    "    y_test = y.loc[test_mask]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = ['year_month', 'year', 'month', 'shop_id', 'item_id', 'item_price']\n",
    "X = sales.loc[:, feat_cols].copy()\n",
    "y = sales.loc[:, 'item_cnt_mth'].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = ts_train_test_split(X, y, test_periods=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201301</td>\n",
       "      <td>2013</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201301</td>\n",
       "      <td>2013</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>1001</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201301</td>\n",
       "      <td>2013</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>10012</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201301</td>\n",
       "      <td>2013</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>1002</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201301</td>\n",
       "      <td>2013</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>1003</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  year_month  year month shop_id item_id  item_price\n",
       "0     201301  2013    01       0    1000        58.0\n",
       "1     201301  2013    01       0    1001        58.0\n",
       "2     201301  2013    01       0   10012        76.0\n",
       "3     201301  2013    01       0    1002        58.0\n",
       "4     201301  2013    01       0    1003        58.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/u1b1700/.pyenv/versions/3.7.2/envs/kag/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "for df in [X_train, X_test]:\n",
    "    df.drop(['year_month', 'year', 'item_price'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestRegressor(n_jobs=4)\n",
    "# params = {'n_estimators': [100, 500, 1000], 'max_depth': [2, 3, 4]}\n",
    "# gs = GridSearchCV(estimator=rf, param_grid=params, verbose=3)\n",
    "# gs.fit(X_train, y_train.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for k in gs.cv_results_.keys():\n",
    "#     print(f'{k}:\\n{gs.cv_results_[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:   44.4s\n",
      "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:  1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor RMSE: 13.235326902255489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 500 out of 500 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=2)]: Done 500 out of 500 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=500, \n",
    "                           criterion='mse', \n",
    "                           max_depth=2, \n",
    "                           min_samples_split=2, \n",
    "                           min_samples_leaf=1, \n",
    "                           min_weight_fraction_leaf=0.0, \n",
    "                           max_features='auto', \n",
    "                           max_leaf_nodes=None, \n",
    "                           min_impurity_decrease=0.0, \n",
    "                           min_impurity_split=None, \n",
    "                           bootstrap=True, \n",
    "                           oob_score=False, \n",
    "                           n_jobs=2, \n",
    "                           random_state=123, \n",
    "                           verbose=1, \n",
    "                           warm_start=False, \n",
    "                           ccp_alpha=0.0, \n",
    "                           max_samples=None)\n",
    "\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'Random Forest Regressor RMSE: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gb = GradientBoostingRegressor(criterion='mse', n_iter_no_change=100)\n",
    "# params = {'n_estimators': [100, 200, 400], \n",
    "#           'max_depth': [2, 3, 4], \n",
    "#           'learning_rate': [0.05, 0.1]}\n",
    "# gs = GridSearchCV(estimator=gb, param_grid=params, n_jobs=1, verbose=3)\n",
    "# gs.fit(X_train, y_train.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for k in gs.cv_results_.keys():\n",
    "#     print(f'{k}:\\n{gs.cv_results_[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_score_idx = np.argmin(gs.cv_results_['rank_test_score'])\n",
    "# gs.cv_results_['params'][best_score_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1          53.8286            3.53m\n",
      "         2          51.9387            3.45m\n",
      "         3          50.4079            3.49m\n",
      "         4          49.1677            3.52m\n",
      "         5          48.1628            3.54m\n",
      "         6          47.3479            3.51m\n",
      "         7          46.6878            3.48m\n",
      "         8          46.2276            3.46m\n",
      "         9          45.7798            3.43m\n",
      "        10          45.4166            3.40m\n",
      "        20          44.3538            3.23m\n",
      "        30          44.2013            2.97m\n",
      "        40          44.0791            2.76m\n",
      "        50          44.0441            2.56m\n",
      "        60          43.9574            2.38m\n",
      "        70          43.8851            2.20m\n",
      "        80          43.7786            2.03m\n",
      "        90          43.7529            1.85m\n",
      "       100          43.6705            1.68m\n",
      "       200          43.2841            0.00s\n",
      "Gradient Boosting Regressor RMSE: 13.205525666865636\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor(loss='ls', \n",
    "                               learning_rate=0.1, \n",
    "                               n_estimators=200, \n",
    "                               subsample=1.0, \n",
    "                               criterion='mse', \n",
    "                               min_samples_split=2, \n",
    "                               min_samples_leaf=1, \n",
    "                               min_weight_fraction_leaf=0.0, \n",
    "                               max_depth=2, \n",
    "                               min_impurity_decrease=0.0, \n",
    "                               min_impurity_split=None, \n",
    "                               init=None, \n",
    "                               random_state=None, \n",
    "                               max_features=None, \n",
    "                               alpha=0.9, \n",
    "                               verbose=1, \n",
    "                               max_leaf_nodes=None, \n",
    "                               warm_start=False, \n",
    "                               presort='deprecated', \n",
    "                               validation_fraction=0.1, \n",
    "                               n_iter_no_change=100, \n",
    "                               tol=0.0001, \n",
    "                               ccp_alpha=0.0)\n",
    "\n",
    "gb.fit(X_train, y_train.values.ravel())\n",
    "y_pred = gb.predict(X_test)\n",
    "\n",
    "score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'Gradient Boosting Regressor RMSE: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical info in shops, potentially\n",
    "A quick glance into the translations of some of the shop_names in shops indicated that I might be able to break out some categorical info. The first word might be a city or some other location. Also, some of the words which have higher frequencies seem to point to either a shopping center, a mall, a megastore, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_names(names_list):\n",
    "    cleaned = []\n",
    "    for n in names_list:\n",
    "        n_cleaned = re.sub(\"[.,\\\")(!]\", \"\", n)\n",
    "        cleaned.append(n_cleaned.upper())\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def tokenize_it(n_list):\n",
    "    return [t.split() for t in n_list]\n",
    "\n",
    "\n",
    "def create_corpus(names_list):\n",
    "    corpus = clean_names(names_list)\n",
    "    corpus = tokenize_it(corpus)\n",
    "    return [' '.join(item) for item in corpus]\n",
    "\n",
    "\n",
    "def get_top_words(df, corpus, top_n):\n",
    "    cvect = CountVectorizer()\n",
    "    count_matrix = cvect.fit_transform(corpus)\n",
    "    word_counts = np.sum(count_matrix.toarray(), axis=0)\n",
    "    vocab = cvect.get_feature_names()\n",
    "    count_rank = np.argsort(word_counts)[::-1]\n",
    "    word_rank = np.array(vocab)[count_rank]  \n",
    "\n",
    "    count_df = pd.DataFrame(data=count_matrix.toarray(), \n",
    "                            columns=vocab)\n",
    "    \n",
    "    df = pd.concat([df, count_df.loc[:, word_rank[:top_n]]], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up names, get locations, then vectorize the top occurences\n",
    "shops['clean_name'] = create_corpus(shops['shop_name'])\n",
    "shops['loc_name'] = shops['clean_name'].apply(lambda x: x.split()[0])\n",
    "shops = get_top_words(shops, shops['clean_name'], 10)\n",
    "\n",
    "# remove top occurences if in loc_name\n",
    "for col in shops.columns:\n",
    "    if col.upper() in shops['loc_name'].unique():\n",
    "        shops.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Aggregrated Sales Data\n",
    "Break out components of date and merge shop info. Then remove columns that don't make sense for modeling and get dummies for location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops['shop_id'] = shops['shop_id'].astype(str)\n",
    "\n",
    "sales['day'] = sales['date'].apply(lambda x: x.day)\n",
    "sales['month'] = sales['date'].apply(lambda x: f'{x.month:02d}')\n",
    "sales['year'] = sales['date'].apply(lambda x: x.year)\n",
    "sales['year_month'] = sales['year'].astype(str) + sales['month'].astype(str)\n",
    "sales['sales_day'] = sales['item_price'] * sales['item_cnt_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales = pd.merge(sales, shops, on='shop_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['shop_name', 'clean_name']\n",
    "for col in drop_cols:\n",
    "    sales.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_cols = ['date_block_num', 'shop_id', 'item_id', 'month', 'year', 'loc_name', \n",
    "           'тц', 'трц', 'мега', 'тк', 'трк', 'молл', 'центральный']\n",
    "\n",
    "model_input = sales.groupby(gb_cols)[['item_cnt_day']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = pd.get_dummies(data=model_input, prefix='loc', prefix_sep='_', \n",
    "                             columns=['loc_name'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_input.drop('item_cnt_day', axis=1)\n",
    "y = model_input.loc[:, 'item_cnt_day']\n",
    "X_train, X_test, y_train, y_test = ts_train_test_split(X, y, test_periods=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [X_train, X_test]:\n",
    "    df.drop(['date_block_num', 'year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=500, \n",
    "                           criterion='mse', \n",
    "                           max_depth=2, \n",
    "                           min_samples_split=2, \n",
    "                           min_samples_leaf=1, \n",
    "                           min_weight_fraction_leaf=0.0, \n",
    "                           max_features='auto', \n",
    "                           max_leaf_nodes=None, \n",
    "                           min_impurity_decrease=0.0, \n",
    "                           min_impurity_split=None, \n",
    "                           bootstrap=True, \n",
    "                           oob_score=False, \n",
    "                           n_jobs=2, \n",
    "                           random_state=123, \n",
    "                           verbose=0, \n",
    "                           warm_start=False, \n",
    "                           ccp_alpha=0.0, \n",
    "                           max_samples=None)\n",
    "\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'Random Forest Regressor RMSE: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor(loss='ls', \n",
    "                               learning_rate=0.1, \n",
    "                               n_estimators=200, \n",
    "                               subsample=1.0, \n",
    "                               criterion='mse', \n",
    "                               min_samples_split=2, \n",
    "                               min_samples_leaf=1, \n",
    "                               min_weight_fraction_leaf=0.0, \n",
    "                               max_depth=2, \n",
    "                               min_impurity_decrease=0.0, \n",
    "                               min_impurity_split=None, \n",
    "                               init=None, \n",
    "                               random_state=None, \n",
    "                               max_features=None, \n",
    "                               alpha=0.9, \n",
    "                               verbose=0, \n",
    "                               max_leaf_nodes=None, \n",
    "                               warm_start=False, \n",
    "                               presort='deprecated', \n",
    "                               validation_fraction=0.1, \n",
    "                               n_iter_no_change=100, \n",
    "                               tol=0.0001, \n",
    "                               ccp_alpha=0.0)\n",
    "\n",
    "gb.fit(X_train, y_train.values.ravel())\n",
    "y_pred = gb.predict(X_test)\n",
    "\n",
    "score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'Gradient Boosting Regressor RMSE: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Insights\n",
    "Decision Tree models not really doing the job we need it to here. The RMSE scores are terrible. Time Series modeling is likely the better approach. Let's see what diffferent aggregations look like. Then, maybe we can pick a particular shop-item combination to use as a template for our TS model..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales overall by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['month'] = sales['month'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.loc[sales['date_block_num'] == 24]['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.loc[(sales['month'] > 9) & (sales['year'] == 2015)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trends(df, title_id):\n",
    "    x = df['year_month']\n",
    "    y1 = df['item_cnt_day']\n",
    "    y2 = df['sales_day']\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(16, 8))\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(x, y1, 'g-', label='Item Count')\n",
    "    ax2.plot(x, y2, 'b-', label='Sales')\n",
    "    \n",
    "    ax1.set_xlabel('Period')\n",
    "    ax1.tick_params(axis='x', rotation=90)\n",
    "    ax1.set_ylabel('Item Count')\n",
    "    ax2.set_ylabel('Sales')\n",
    "    fig.legend()\n",
    "#     ax2.legend(loc='best')\n",
    "    plt.title(f'{title_id}\\nItem Count & Sales')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "overall = sales.groupby(['year_month'])[['item_cnt_day', 'sales_day']].sum().reset_index()\n",
    "overall.sort_values(['year_month'], inplace=True)\n",
    "plot_trends(overall, 'Overall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales by City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_cols = ['loc_name', 'year_month']\n",
    "city_sales = sales.groupby(gb_cols)[['item_cnt_day', 'sales_day']].sum().reset_index()\n",
    "\n",
    "for n in sorted(city_sales['loc_name'].unique()):\n",
    "    print(f'********\\n{n}\\n********\\n')\n",
    "    subdf = city_sales.loc[city_sales['loc_name'] == n]\n",
    "    print(subdf.shape)\n",
    "    plot_trends(subdf, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales by the location types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loc_types = ['тц', 'трц', 'мега', 'тк', 'трк', 'молл', 'центральный']\n",
    "\n",
    "for t in loc_types:\n",
    "    print(f'********\\n{t}\\n********\\n')\n",
    "    subdf = sales.loc[sales[t] == 1]\n",
    "    subdf = subdf.groupby(['year_month'])[['item_cnt_day', 'sales_day']].sum().reset_index()\n",
    "    plot_trends(subdf, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item Categories\n",
    "Most item categories appear to have a more general category description. Break this out into its own column. Then, merge categories to items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split on hyphen\n",
    "mask = cats['item_category_name'].str.contains(' -')\n",
    "cats.loc[mask, 'major_category'] =  cats.loc[\n",
    "    mask, 'item_category_name'].apply(lambda x: x.split(' -')[0])\n",
    "\n",
    "# get description before parenthesis\n",
    "mask1 = cats['item_category_name'].str.contains(' \\(')\n",
    "mask2 = cats['major_category'].isna()\n",
    "cats.loc[mask1 & mask2, 'major_category'] =  cats.loc[\n",
    "    mask1 & mask2, 'item_category_name'].apply(lambda x: x.split(' (')[0])\n",
    "\n",
    "# whatever is left\n",
    "mask = cats['major_category'].isna()\n",
    "cats.loc[mask, 'major_category'] =  cats.loc[mask, 'item_category_name']\n",
    "\n",
    "items = pd.merge(items, cats, on=['item_category_id'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales by Major Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.merge(sales, items, on=['item_id'], how='inner')\n",
    "\n",
    "for cat in sorted(sales['major_category'].unique()):\n",
    "    print(f'**********\\n{cat}\\n**********')\n",
    "    subdf = sales.loc[sales['major_category'] == cat]\n",
    "    subdf = subdf.groupby('year_month')[['item_cnt_day', 'sales_day']].sum().reset_index()\n",
    "    plot_trends(subdf, cat)\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focus on Tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_majorcat = 'Игры'\n",
    "top_loc = 'МОСКВА'\n",
    "top_loc_type = 'тц'\n",
    "top_shop_id = 31\n",
    "top_cat = 'Игры - XBOX 360'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majorcat_mask = sales['major_category'] == top_majorcat\n",
    "loc_mask = sales['loc_name'] == top_loc\n",
    "shop_mask = sales['shop_id'] == top_shop_id\n",
    "cat_mask = sales['item_category_name'] == top_cat\n",
    "\n",
    "top_catloc = sales.loc[majorcat_mask & \n",
    "                       loc_mask & \n",
    "                       shop_mask & \n",
    "                       cat_mask &\n",
    "                       (sales[top_loc_type] == 1)]\n",
    "top_catloc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_catloc['item_category_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_items = top_catloc.groupby(['item_name', 'item_id'])[['item_cnt_day', 'sales_day']].sum().reset_index()\n",
    "top_items.sort_values(['item_cnt_day'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_items.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.loc[items['item_id'] == 3342]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_catloc['item_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_catloc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cat_name in sorted(top_catloc['item_category_name'].unique()):\n",
    "    print(f'*********\\n{cat_name}\\n***********')\n",
    "    subdf = top_catloc.loc[top_catloc['item_category_name'] == cat_name]\n",
    "    subdf = subdf.groupby('year_month')[['item_cnt_day', 'sales_day']].sum().reset_index()\n",
    "    plot_trends(subdf, cat_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_cols = ['shop_id', 'shop_name', 'clean_name', 'loc_name',\n",
    "           'тц', 'трц', 'мега', 'тк', 'трк', 'молл', 'центральный']\n",
    "shop_agg = top_catloc.groupby(gb_cols)[['item_cnt_day', 'sales_day']].sum().reset_index()\n",
    "shop_agg.sort_values('item_cnt_day', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['major_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats.loc[cats['major_category'] == 'Книги']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['item_category_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.loc[items['item_category_id'] == 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats.loc[40:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP on Shop Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = create_corpus(shop_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "vect_matrix = vect.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_array = vect_matrix.toarray()\n",
    "count_array = count_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(count_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(tfidf_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(cleaned_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
